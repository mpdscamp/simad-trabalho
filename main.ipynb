{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇  Downloading Portuguese word list …\n",
      "✓ Saved to data\\dict_ptbr.txt\n",
      "Dictionary ready – 177,953 words ≤10 letters (accents removed)\n",
      "Running sanity demo …\n",
      "       secret  attempts   won\n",
      "0    TREMELAL         3  True\n",
      "1    ESCANSAO         5  True\n",
      "2    ALOQUIRO         3  True\n",
      "3  ENGALANEAR         3  True\n",
      "4      TURURI         4  True\n",
      "Mean attempts : 3.6786\n",
      "Win rate      : 0.9988\n",
      "\n",
      "Quick experiment (Random × Elimination × Entropy)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Letroso Simulation & Analysis Toolkit\n",
    "====================================\n",
    "\n",
    "A single-file, notebook‑friendly implementation that covers:\n",
    "  • Portuguese dictionary download & cleansing (≤10‑letter words)\n",
    "  • Core feedback logic (green / yellow / grey)\n",
    "  • Three playing strategies\n",
    "      – Random (baseline)\n",
    "      – Elimination (candidate‑pruning)\n",
    "      – Entropy / information‑gain (heuristic optimal)\n",
    "  • Monte‑Carlo harness with optional multiprocessing\n",
    "  • Confidence‑interval helper\n",
    "  • Exhaustive toy‑validation utility\n",
    "  • Experiment runner producing a tidy pandas DataFrame\n",
    "  • Convenience plot helpers (histogram & CDF)\n",
    "  • Minimal __main__ demo\n",
    "\n",
    "Each logical section is delimited by `# %%` so the file doubles as a\n",
    "Jupyter‑compatible *percent‑script* (you can `jupyter nbconvert` it or open\n",
    "directly in VS Code / JupyterLab).\n",
    "\n",
    "Requires Python ≥ 3.11 and the packages listed in `requirements.txt`.\n",
    "\"\"\"\n",
    "\n",
    "# %% Imports & basic setup ----------------------------------------------------\n",
    "from __future__ import annotations\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import urllib.request\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode  # strip accents\n",
    "from scipy import stats\n",
    "\n",
    "# Reproducibility -------------------------------------------------------------\n",
    "RNG = random.Random(42)\n",
    "\n",
    "# Colour codes ----------------------------------------------------------------\n",
    "GREEN, YELLOW, GREY = \"G\", \"Y\", \"-\"\n",
    "\n",
    "# Aliases ---------------------------------------------------------------------\n",
    "Word = str\n",
    "Feedback = Tuple[str, ...]  # e.g. (\"G\", \"Y\", \"-\", ...)\n",
    "Strategy = \"BaseStrategy\"   # forward ref for type checker\n",
    "\n",
    "# %% Portuguese dictionary ----------------------------------------------------\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "DICT_PATH = DATA_DIR / \"dict_ptbr.txt\"\n",
    "DICT_URL = (\n",
    "    \"https://raw.githubusercontent.com/\"\n",
    "    \"pythonprobr/palavras/master/palavras.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def _download_dictionary(dest: pathlib.Path, url: str = DICT_URL) -> None:\n",
    "    dest.parent.mkdir(exist_ok=True)\n",
    "    print(\"⬇  Downloading Portuguese word list …\")\n",
    "    urllib.request.urlretrieve(url, dest)\n",
    "    print(\"✓ Saved to\", dest)\n",
    "\n",
    "\n",
    "def load_dictionary_pt(max_len: int = 10, asciify: bool = True) -> List[Word]:\n",
    "    \"\"\"Return uppercase Portuguese words ≤ *max_len* letters.\"\"\"\n",
    "    if not DICT_PATH.exists():\n",
    "        _download_dictionary(DICT_PATH)\n",
    "\n",
    "    words: list[Word] = []\n",
    "    with open(DICT_PATH, encoding=\"utf-8\") as fh:\n",
    "        for w in fh:\n",
    "            w = w.strip()\n",
    "            if 0 < len(w) <= max_len and w.isalpha():\n",
    "                if asciify:\n",
    "                    w = unidecode.unidecode(w)\n",
    "                words.append(w.upper())\n",
    "    return words\n",
    "\n",
    "\n",
    "DICT: List[Word] = load_dictionary_pt()\n",
    "print(f\"Dictionary ready – {len(DICT):,} words ≤10 letters (accents removed)\")\n",
    "\n",
    "# %% Core game logic ----------------------------------------------------------\n",
    "\n",
    "def feedback(secret: Word, guess: Word) -> Feedback:\n",
    "    \"\"\"Return tuple of colour codes for *guess* compared to *secret*.\"\"\"\n",
    "    if len(secret) != len(guess):\n",
    "        raise ValueError(\"Secret and guess must have the same length\")\n",
    "\n",
    "    result = [GREY] * len(secret)\n",
    "    remaining = Counter(secret)\n",
    "\n",
    "    # Pass 1 – mark greens\n",
    "    for i, (s, g) in enumerate(zip(secret, guess)):\n",
    "        if s == g:\n",
    "            result[i] = GREEN\n",
    "            remaining[g] -= 1\n",
    "\n",
    "    # Pass 2 – mark yellows\n",
    "    for i, (s, g) in enumerate(zip(secret, guess)):\n",
    "        if result[i] == GREY and remaining[g] > 0:\n",
    "            result[i] = YELLOW\n",
    "            remaining[g] -= 1\n",
    "\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "# Self‑check ------------------------------------------------------------------\n",
    "assert feedback(\"BANANA\", \"BACIAS\") == (\n",
    "    GREEN,\n",
    "    GREEN,\n",
    "    GREY,\n",
    "    GREY,\n",
    "    YELLOW,\n",
    "    GREY,\n",
    ")\n",
    "\n",
    "# %% Strategy hierarchy -------------------------------------------------------\n",
    "@dataclass\n",
    "class BaseStrategy:\n",
    "    \"\"\"Uniform‑random baseline. Override *update* for smarter play.\"\"\"\n",
    "\n",
    "    dictionary: List[Word]\n",
    "\n",
    "    # Runtime attributes (populated by *reset*)\n",
    "    candidates: List[Word] = None  # type: ignore\n",
    "    history: List[Tuple[Word, Feedback]] = None  # type: ignore\n",
    "\n",
    "    def reset(self, word_len: int) -> None:\n",
    "        self.candidates = [w for w in self.dictionary if len(w) == word_len]\n",
    "        self.history = []\n",
    "\n",
    "    def next_guess(self) -> Word:\n",
    "        return RNG.choice(self.candidates)\n",
    "\n",
    "    def update(self, guess: Word, fb: Feedback) -> None:\n",
    "        self.history.append((guess, fb))\n",
    "\n",
    "\n",
    "class EliminationStrategy(BaseStrategy):\n",
    "    \"\"\"Keeps only words consistent with all past feedback (Knuth‑style).\"\"\"\n",
    "\n",
    "    def _consistent(self, word: Word, guess: Word, fb: Feedback) -> bool:\n",
    "        return feedback(word, guess) == fb\n",
    "\n",
    "    def update(self, guess: Word, fb: Feedback) -> None:\n",
    "        super().update(guess, fb)\n",
    "        self.candidates = [w for w in self.candidates if self._consistent(w, guess, fb)]\n",
    "\n",
    "\n",
    "class EntropyStrategy(EliminationStrategy):\n",
    "    \"\"\"Selects guess that minimises expected remaining search space.\"\"\"\n",
    "\n",
    "    SAMPLE_LIMIT = 2000  # speed trade‑off for large candidate sets\n",
    "\n",
    "    def next_guess(self) -> Word:\n",
    "        best_word: Word | None = None\n",
    "        best_score = float(\"inf\")\n",
    "\n",
    "        pool = (\n",
    "            self.candidates\n",
    "            if len(self.candidates) <= self.SAMPLE_LIMIT\n",
    "            else RNG.sample(self.candidates, self.SAMPLE_LIMIT)\n",
    "        )\n",
    "\n",
    "        for word in pool:\n",
    "            bucket_sizes: defaultdict[Feedback, int] = defaultdict(int)\n",
    "            for secret in self.candidates:\n",
    "                bucket_sizes[feedback(secret, word)] += 1\n",
    "            exp_remaining = sum(n * n for n in bucket_sizes.values()) / len(self.candidates)\n",
    "            if exp_remaining < best_score:\n",
    "                best_word, best_score = word, exp_remaining\n",
    "\n",
    "        return best_word or RNG.choice(self.candidates)\n",
    "\n",
    "\n",
    "# %% Simulation engine --------------------------------------------------------\n",
    "@dataclass\n",
    "class GameResult:\n",
    "    secret: Word\n",
    "    attempts: int\n",
    "    won: bool\n",
    "\n",
    "\n",
    "def play_game(secret: Word, strategy: Strategy, max_attempts: int = 10) -> GameResult:\n",
    "    strategy.reset(len(secret))\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        guess = strategy.next_guess()\n",
    "        fb = feedback(secret, guess)\n",
    "        if all(c == GREEN for c in fb):\n",
    "            return GameResult(secret, attempt, True)\n",
    "        strategy.update(guess, fb)\n",
    "    return GameResult(secret, max_attempts, False)\n",
    "\n",
    "\n",
    "# %% Monte‑Carlo harness & CI -------------------------------------------------\n",
    "\n",
    "def run_many(\n",
    "    n_games: int,\n",
    "    strat_cls,\n",
    "    dictionary: List[Word] = DICT,\n",
    "    n_jobs: int = 1,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Simulate *n_games* and return a DataFrame (one row per game).\"\"\"\n",
    "\n",
    "    if n_jobs == 1:\n",
    "        results = [\n",
    "            play_game(RNG.choice(dictionary), strat_cls(dictionary)) for _ in range(n_games)\n",
    "        ]\n",
    "    else:\n",
    "        import multiprocessing as mp\n",
    "\n",
    "        with mp.Pool(n_jobs) as pool:\n",
    "            results = pool.starmap(\n",
    "                play_game,\n",
    "                [\n",
    "                    (RNG.choice(dictionary), strat_cls(dictionary))\n",
    "                    for _ in range(n_games)\n",
    "                ],\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame([r.__dict__ for r in results])\n",
    "\n",
    "\n",
    "def ci_mean(series: pd.Series, alpha: float = 0.05) -> tuple[float, float]:\n",
    "    m = series.mean()\n",
    "    h = stats.t.ppf(1 - alpha / 2, len(series) - 1) * series.std(ddof=1) / (len(series) ** 0.5)\n",
    "    return m - h, m + h\n",
    "\n",
    "\n",
    "# %% Validation utility -------------------------------------------------------\n",
    "\n",
    "def exhaustive_validation() -> None:\n",
    "    \"\"\"Run analytic vs simulated win‑rate on an exhaustive toy dictionary.\"\"\"\n",
    "\n",
    "    toy = [\"AAA\", \"AAB\", \"ABA\", \"ABB\", \"BAA\", \"BAB\", \"BBA\", \"BBB\"]\n",
    "    analytic = 1 - (1 - 1 / len(toy)) ** 10  # random guesses w/ replacement\n",
    "    df = run_many(50_000, BaseStrategy, toy)\n",
    "    sim = df[\"won\"].mean()\n",
    "    print(\n",
    "        f\"Validation toy‑dict ⇒ analytic={analytic:.4f}  simulation={sim:.4f}  Δ={(sim-analytic):+.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# %% Experiment & plots -------------------------------------------------------\n",
    "\n",
    "def experiment(replications: int = 20_000, n_jobs: int = 1) -> pd.DataFrame:\n",
    "    scenarios = {\n",
    "        \"Random\": BaseStrategy,\n",
    "        \"Elimination\": EliminationStrategy,\n",
    "        \"Entropy\": EntropyStrategy,\n",
    "    }\n",
    "    rows: list[dict] = []\n",
    "    for name, strat in scenarios.items():\n",
    "        df = run_many(replications, strat, n_jobs=n_jobs)\n",
    "        mu = df[\"attempts\"].mean()\n",
    "        ci_low, ci_high = ci_mean(df[\"attempts\"])\n",
    "        rows.append(\n",
    "            dict(\n",
    "                Strategy=name,\n",
    "                MeanAttempts=mu,\n",
    "                CI_low=ci_low,\n",
    "                CI_high=ci_high,\n",
    "                WinRate=df[\"won\"].mean(),\n",
    "            )\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_hist(df: pd.DataFrame, label: str) -> None:\n",
    "    df[\"attempts\"].hist(bins=range(1, 12), rwidth=0.8)\n",
    "    plt.title(f\"Distribution of attempts – {label}\")\n",
    "    plt.xlabel(\"Attempts\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cdf(df_a: pd.DataFrame, df_b: pd.DataFrame, label_a: str, label_b: str) -> None:\n",
    "    plt.figure()\n",
    "    for df, label in ((df_a, label_a), (df_b, label_b)):\n",
    "        data = sorted(df[\"attempts\"].to_list())\n",
    "        y = [i / len(data) for i in range(1, len(data) + 1)]\n",
    "        plt.step(data, y, where=\"post\", label=label)\n",
    "    plt.xlabel(\"Attempts\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(\"CDF of attempts\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# %% Main demo ----------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running sanity demo …\")\n",
    "    df_demo = run_many(5_000, EliminationStrategy)\n",
    "    print(df_demo.head())\n",
    "    print(\"Mean attempts :\", df_demo[\"attempts\"].mean())\n",
    "    print(\"Win rate      :\", df_demo[\"won\"].mean())\n",
    "\n",
    "    print(\"\\nQuick experiment (Random × Elimination × Entropy)\")\n",
    "    print(experiment(replications=5_000))\n",
    "\n",
    "    # Uncomment for validation & plots\n",
    "    # exhaustive_validation()\n",
    "    # plot_hist(run_many(10_000, BaseStrategy), \"Random\")\n",
    "    # plot_hist(run_many(10_000, EliminationStrategy), \"Elimination\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
